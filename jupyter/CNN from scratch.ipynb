{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is intended for CIFAR-10 object recognition using CNN from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten, Activation, add\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import backend as ktf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.datasets import cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, read the data, and normalize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read data saved in Keras\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# check data size\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "# normalize them to 0 mean and unit variance\n",
    "data = ImageDataGenerator(samplewise_center=True,\n",
    "                          samplewise_std_normalization=True,\n",
    "                          featurewise_center=False,\n",
    "                          featurewise_std_normalization=False)\n",
    "data.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimpleCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use a simple CNN model and train it from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model architecture\n",
    "# [batchnorm-Conv-Conv-maxpool]x2 - [dense]x2 - [softmax]\n",
    "simple_CNN = Sequential()\n",
    "simple_CNN.add(BatchNormalization(input_shape=(32, 32, 3)))\n",
    "simple_CNN.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "simple_CNN.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "simple_CNN.add(MaxPooling2D((2, 2))) # (16,16,32)\n",
    "\n",
    "simple_CNN.add(BatchNormalization())\n",
    "simple_CNN.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "simple_CNN.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "simple_CNN.add(MaxPooling2D((2, 2))) # (8,8,64)\n",
    "\n",
    "simple_CNN.add(Flatten())\n",
    "simple_CNN.add(Dense(2048, activation='relu'))\n",
    "simple_CNN.add(Dropout(0.45))\n",
    "simple_CNN.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# set loss and optimizer\n",
    "rmsprop = RMSprop(lr=0.001, decay=0.99)\n",
    "simple_CNN.compile(loss='sparse_categorical_crossentropy', optimizer=rmsprop, metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "checkpoint = ModelCheckpoint('../models/simpleCNN_{epoch:02d}-{loss:.4f}.h5',\n",
    "                             monitor='loss',\n",
    "                             save_best_only=True)\n",
    "earlystop = EarlyStopping(min_delta=0.0001, patience=3)\n",
    "\n",
    "simple_CNN.fit_generator(generator=data.flow(x_train, y_train, batch_size=64),\n",
    "                         steps_per_epoch=len(x_train)/64,\n",
    "                         initial_epoch=0,\n",
    "                         epochs=10,\n",
    "                         callbacks=[],\n",
    "                         validation_data=(x_test,y_test.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
